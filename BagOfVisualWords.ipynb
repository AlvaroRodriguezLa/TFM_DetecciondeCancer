{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "TP7GYz5MGeDb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alvaro.rlanceta\\AppData\\Local\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import copy\n",
    "import time\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from PIL import Image\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from glob import glob\n",
    "from skimage.io import imread\n",
    "from os import listdir\n",
    "import cv2\n",
    "\n",
    "from scipy import ndimage\n",
    "from scipy.spatial import distance\n",
    "from sklearn.cluster import KMeans\n",
    "#import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "6hHei77OGeDh"
   },
   "outputs": [],
   "source": [
    "# Ruta de la carpeta principal\n",
    "main_folder = \"C:\\\\Users\\\\alvaro.rlanceta\\\\Documents\\\\tfm\\\\datasetstfm\\\\datasets_D\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "def load_and_extract_features(folder, max_images_per_class=None):\n",
    "    images = []\n",
    "    labels = []\n",
    "    descriptors_list = []\n",
    "    sift = cv2.SIFT_create()\n",
    "    count_per_class = {}\n",
    "\n",
    "    for label in sorted(os.listdir(folder)):\n",
    "        class_folder = os.path.join(folder, label)\n",
    "        count_per_class[label] = 0  # Inicializar contador para cada clase\n",
    "\n",
    "        for filename in os.listdir(class_folder):\n",
    "            if max_images_per_class is not None and count_per_class[label] >= max_images_per_class:\n",
    "                continue  # Pasar a la siguiente clase si ya se alcanzó el límite\n",
    "\n",
    "            img_path = os.path.join(class_folder, filename)\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if img is not None:\n",
    "                keypoints, descriptors = sift.detectAndCompute(img, None)\n",
    "                if descriptors is not None:\n",
    "                    images.append(img)\n",
    "                    labels.append(int(label))\n",
    "                    descriptors_list.append(descriptors)\n",
    "                    count_per_class[label] += 1\n",
    "\n",
    "            if max_images_per_class is not None and all(count >= max_images_per_class for count in count_per_class.values()):\n",
    "                break  # Terminar completamente si todas las clases alcanzaron el límite\n",
    "\n",
    "    return images, labels, descriptors_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_histograms(kmeans, descriptors_list):\n",
    "    histograms = []\n",
    "    for descriptors in descriptors_list:\n",
    "        histogram = np.zeros(len(kmeans.cluster_centers_))\n",
    "        clusters = kmeans.predict(descriptors)\n",
    "        for i in clusters:\n",
    "            histogram[i] += 1\n",
    "        histograms.append(histogram)\n",
    "    return histograms\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "def kmeans_clustering(descriptors_list, K):\n",
    "    # Concatenar todos los descriptores en una sola lista de numpy para k-means\n",
    "    all_descriptors = np.vstack(descriptors_list)\n",
    "    kmeans = KMeans(n_clusters=K, random_state=0).fit(all_descriptors)\n",
    "    return kmeans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# Tiempo inicial\n",
    "start_time = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels, train_descriptors = load_and_extract_features(main_folder + \"\\\\train\", 20000)\n",
    "\n",
    "# Clustering para formar el vocabulario\n",
    "kmeans = kmeans_clustering(train_descriptors, K=200)  # Número de visual words\n",
    "\n",
    "# Construir histogramas\n",
    "train_histograms = build_histograms(kmeans, train_descriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecución: 0:32:06.560338\n"
     ]
    }
   ],
   "source": [
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Calculando la diferencia de tiempo\n",
    "duration = end_time - start_time\n",
    "\n",
    "print(f\"Tiempo de ejecución: {duration}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_histograms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def train_svm(histograms, labels):\n",
    "    classifier = SVC(kernel='linear', probability=True)\n",
    "    classifier.fit(histograms, labels)\n",
    "    return classifier\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "def train_naive_bayes(histograms, labels):\n",
    "    # Uso de BernoulliNB que podría ser más adecuado para características binarias/histogramas\n",
    "    classifier = make_pipeline(StandardScaler(), BernoulliNB())\n",
    "    classifier.fit(histograms, labels)\n",
    "    return classifier\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "def train_neural_network(histograms, labels):\n",
    "    model = Sequential([\n",
    "        Dense(512, activation='relu', input_shape=(histograms.shape[1],)),\n",
    "        Dropout(0.5),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(histograms, labels, epochs=40, batch_size=32, verbose=1)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecución: 1:32:21.835547\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.datetime.now()\n",
    "svm_classifier = train_svm(train_histograms, train_labels)\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Calculando la diferencia de tiempo\n",
    "duration = end_time - start_time\n",
    "\n",
    "print(f\"Tiempo de ejecución: {duration}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "1250/1250 [==============================] - 15s 9ms/step - loss: 0.6338 - accuracy: 0.6477\n",
      "Epoch 2/40\n",
      "1250/1250 [==============================] - 12s 9ms/step - loss: 0.6108 - accuracy: 0.6730\n",
      "Epoch 3/40\n",
      "1250/1250 [==============================] - 12s 9ms/step - loss: 0.5992 - accuracy: 0.6823\n",
      "Epoch 4/40\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 0.5847 - accuracy: 0.6928\n",
      "Epoch 5/40\n",
      "1250/1250 [==============================] - 12s 9ms/step - loss: 0.5694 - accuracy: 0.7067\n",
      "Epoch 6/40\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 0.5499 - accuracy: 0.7214\n",
      "Epoch 7/40\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 0.5288 - accuracy: 0.7354\n",
      "Epoch 8/40\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 0.5015 - accuracy: 0.7545\n",
      "Epoch 9/40\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 0.4802 - accuracy: 0.7678\n",
      "Epoch 10/40\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 0.4587 - accuracy: 0.7814\n",
      "Epoch 11/40\n",
      "1250/1250 [==============================] - 12s 9ms/step - loss: 0.4402 - accuracy: 0.7919\n",
      "Epoch 12/40\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 0.4237 - accuracy: 0.8004\n",
      "Epoch 13/40\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 0.4043 - accuracy: 0.8115\n",
      "Epoch 14/40\n",
      "1250/1250 [==============================] - 12s 9ms/step - loss: 0.3879 - accuracy: 0.8188\n",
      "Epoch 15/40\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 0.3813 - accuracy: 0.8238\n",
      "Epoch 16/40\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 0.3657 - accuracy: 0.8336\n",
      "Epoch 17/40\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 0.3524 - accuracy: 0.8377\n",
      "Epoch 18/40\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 0.3458 - accuracy: 0.8438\n",
      "Epoch 19/40\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 0.3328 - accuracy: 0.8478\n",
      "Epoch 20/40\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 0.3280 - accuracy: 0.8535\n",
      "Epoch 21/40\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 0.3204 - accuracy: 0.8580\n",
      "Epoch 22/40\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 0.3160 - accuracy: 0.8581\n",
      "Epoch 23/40\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 0.3043 - accuracy: 0.8665\n",
      "Epoch 24/40\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 0.3011 - accuracy: 0.8677\n",
      "Epoch 25/40\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 0.2912 - accuracy: 0.8711\n",
      "Epoch 26/40\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 0.2907 - accuracy: 0.8709\n",
      "Epoch 27/40\n",
      "1250/1250 [==============================] - 12s 9ms/step - loss: 0.2844 - accuracy: 0.8762\n",
      "Epoch 28/40\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 0.2775 - accuracy: 0.8784\n",
      "Epoch 29/40\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 0.2710 - accuracy: 0.8835\n",
      "Epoch 30/40\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 0.2654 - accuracy: 0.8847\n",
      "Epoch 31/40\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 0.2578 - accuracy: 0.8885\n",
      "Epoch 32/40\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 0.2566 - accuracy: 0.8906\n",
      "Epoch 33/40\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 0.2523 - accuracy: 0.8902\n",
      "Epoch 34/40\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 0.2539 - accuracy: 0.8910\n",
      "Epoch 35/40\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 0.2463 - accuracy: 0.8937\n",
      "Epoch 36/40\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 0.2416 - accuracy: 0.8966\n",
      "Epoch 37/40\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 0.2386 - accuracy: 0.8990\n",
      "Epoch 38/40\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 0.2371 - accuracy: 0.8989\n",
      "Epoch 39/40\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 0.2331 - accuracy: 0.9023\n",
      "Epoch 40/40\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 0.2308 - accuracy: 0.9016\n",
      "Tiempo de ejecución: 0:07:35.696776\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.datetime.now()\n",
    "\n",
    "nn_classifier = train_neural_network(np.array(train_histograms), np.array(train_labels))\n",
    "    \n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Calculando la diferencia de tiempo\n",
    "duration = end_time - start_time\n",
    "\n",
    "print(f\"Tiempo de ejecución: {duration}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecución: 0:00:01.207062\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.datetime.now()\n",
    "\n",
    "nb_classifier = train_naive_bayes(train_histograms, train_labels)\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Calculando la diferencia de tiempo\n",
    "duration = end_time - start_time\n",
    "\n",
    "print(f\"Tiempo de ejecución: {duration}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def evaluate_classifiers(classifiers, test_histograms, test_labels):\n",
    "    results = {}\n",
    "    for name, classifier in classifiers.items():\n",
    "        if name == 'Neural Network':\n",
    "            predictions = classifier.predict(test_histograms) \n",
    "        else:\n",
    "            predictions = classifier.predict(test_histograms)\n",
    "        results[name] = classification_report(test_labels, predictions, target_names=['Class 0', 'Class 1'])\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_extract_featuresT(folder, max_images_per_class=None, sift=cv2.SIFT_create()):\n",
    "    images = []\n",
    "    labels = []\n",
    "    descriptors_list = []\n",
    "    count_per_class = {}\n",
    "\n",
    "    for label in sorted(os.listdir(folder)):\n",
    "        class_folder = os.path.join(folder, label)\n",
    "        count_per_class[label] = 0  # Inicializar contador para cada clase\n",
    "\n",
    "        for filename in os.listdir(class_folder):\n",
    "            if max_images_per_class is not None and count_per_class[label] >= max_images_per_class:\n",
    "                continue  # Pasar a la siguiente clase si ya se alcanzó el límite\n",
    "\n",
    "            img_path = os.path.join(class_folder, filename)\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if img is not None:\n",
    "                keypoints, descriptors = sift.detectAndCompute(img, None)\n",
    "                if descriptors is not None:\n",
    "                    images.append(img)\n",
    "                    labels.append(int(label))\n",
    "                    descriptors_list.append(descriptors)\n",
    "                    count_per_class[label] += 1\n",
    "\n",
    "            if max_images_per_class is not None and all(count >= max_images_per_class for count in count_per_class.values()):\n",
    "                break  # Terminar completamente si todas las clases alcanzaron el límite\n",
    "\n",
    "    return images, labels, descriptors_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 2ms/step\n",
      "Results for SVM:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.76      0.58      0.66       500\n",
      "     Class 1       0.66      0.81      0.73       500\n",
      "\n",
      "    accuracy                           0.70      1000\n",
      "   macro avg       0.71      0.70      0.69      1000\n",
      "weighted avg       0.71      0.70      0.69      1000\n",
      "\n",
      "Results for Naive Bayes:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.75      0.66      0.70       500\n",
      "     Class 1       0.70      0.78      0.74       500\n",
      "\n",
      "    accuracy                           0.72      1000\n",
      "   macro avg       0.72      0.72      0.72      1000\n",
      "weighted avg       0.72      0.72      0.72      1000\n",
      "\n",
      "Results for Neural Network:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.67      0.73      0.70       500\n",
      "     Class 1       0.70      0.63      0.67       500\n",
      "\n",
      "    accuracy                           0.68      1000\n",
      "   macro avg       0.68      0.68      0.68      1000\n",
      "weighted avg       0.68      0.68      0.68      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_images, test_labels, test_descriptors = load_and_extract_featuresT(main_folder + \"\\\\test\", 500)\n",
    "test_histograms = build_histograms(kmeans, test_descriptors)\n",
    "\n",
    "# Evaluar los clasificadores\n",
    "classifiers = {\n",
    "    'SVM': svm_classifier,\n",
    "    'Naive Bayes': nb_classifier,\n",
    "    'Neural Network': nn_classifier\n",
    "}\n",
    "evaluation_results = evaluate_classifiers(classifiers, np.array(test_histograms), np.array(test_labels))\n",
    "\n",
    "for result in evaluation_results:\n",
    "    print(f\"Results for {result}:\")\n",
    "    print(evaluation_results[result])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mtL-ZpabGeDt"
   },
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    acc_history = {\"train\": [], \"val\": []}\n",
    "    losses = {\"train\": [], \"val\": []}\n",
    "\n",
    "    # we will keep a copy of the best weights so far according to validation accuracy\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    losses[phase].append(loss.item())\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data).cpu().numpy()\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            \n",
    "            acc_history[phase].append(epoch_acc)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, acc_history, losses\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aw7WLTq3GeDv"
   },
   "outputs": [],
   "source": [
    "def initialize_model(num_classes):\n",
    "    # Resnet18 \n",
    "    model = models.resnet18()\n",
    "    \n",
    "    model.fc = nn.Linear(512, num_classes)\n",
    "    \n",
    "    input_size = 224\n",
    "        \n",
    "    return model, input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ggBfYEQ8GeDw",
    "outputId": "c3c523fe-5052-455e-ff88-ef841177e7db"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Number of classes in the dataset\n",
    "num_classes = 2\n",
    "\n",
    "# Initialize the model\n",
    "model, input_size = initialize_model(num_classes)\n",
    "\n",
    "# Print the model we just instantiated\n",
    "print(model)\n",
    "\n",
    "# Send the model to GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bvt0DuzGGeDx"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Setup the loss fxn\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Number of epochs to train for \n",
    "num_epochs = 40\n",
    "\n",
    "optimizer_ft = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1oEex6gWGeDx",
    "outputId": "adc57665-eb85-4d20-f401-b9ad3c9493ac"
   },
   "outputs": [],
   "source": [
    "# Train and evaluate\n",
    "model, hist, losses = train_model(model, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VR9CgnFBGeDy"
   },
   "outputs": [],
   "source": [
    "# Plot the losses and accuracies\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "ax1.plot(losses[\"train\"], label=\"training loss\")\n",
    "ax1.plot(losses[\"val\"], label=\"validation loss\")\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(hist[\"train\"],label=\"training accuracy\")\n",
    "ax2.plot(hist[\"val\"],label=\"val accuracy\")\n",
    "ax2.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_indices_test = torch.randperm(len(image_datasets['test']))[:int(0.3*len(image_datasets['test']))]\n",
    "test_data_subset = torch.utils.data.Subset(image_datasets['test'], subset_indices_test)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_data_subset, batch_size=batch_size, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_corrects += torch.sum(preds == labels.data).item()\n",
    "\n",
    "    loss = running_loss / len(dataloader.dataset)\n",
    "    accuracy = running_corrects / len(dataloader.dataset)\n",
    "\n",
    "    return loss, accuracy\n",
    "\n",
    "test_loss, test_accuracy = evaluate_model(model, test_dataloader)\n",
    "\n",
    "print('Test Loss: {:.4f}, Test Accuracy: {:.4f}'.format(test_loss, test_accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_img_names = []\n",
    "\n",
    "counter = 0\n",
    "for i, (inputs, labels) in enumerate(test_dataloader):\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "    for j in range(inputs.size(0)):\n",
    "        # Obtener el nombre de la imagen\n",
    "        image_index = i * test_dataloader.batch_size + j\n",
    "        image_path = test_data_subset.dataset.samples[image_index][0]\n",
    "        image_name = os.path.basename(image_path)\n",
    "        print(\"Nombre de la imagen: {}\".format(image_name))\n",
    "        list_img_names.append(image_name)\n",
    "        # Loading and showing the image\n",
    "        image = inputs[j].permute(1, 2, 0).cpu().numpy()\n",
    "\n",
    "        # Normalizing the image\n",
    "        image = (image - image.min()) / (image.max() - image.min())\n",
    "\n",
    "        \"\"\"\n",
    "        plt.figure()\n",
    "        plt.imshow(image)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        \"\"\"\n",
    "        # Print the prediction and the correct label\n",
    "        prediction = preds[j].item()\n",
    "        correct_label = labels[j].item()\n",
    "        print(\"Predicción: {}, Etiqueta correcta: {}\".format(prediction, correct_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_ids = []\n",
    "for name in list_img_names:\n",
    "    id = name.split('_')[0]\n",
    "    patient_ids.append(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_unique = list(set(patient_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = main_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_cancer_dataframe(patient_id, cancer_id):\n",
    "    path = os.path.join(base_path, patient_id, cancer_id)\n",
    "    files = os.listdir(path)\n",
    "    dataframe = pd.DataFrame(files, columns=[\"filename\"])\n",
    "    path_names = [os.path.join(path, filename) for filename in dataframe.filename.values]\n",
    "    dataframe = dataframe.filename.str.rsplit(\"_\", n=4, expand=True)\n",
    "    dataframe.loc[:, \"target\"] = np.int(cancer_id)\n",
    "    dataframe.loc[:, \"path\"] = path_names\n",
    "    dataframe = dataframe.drop([0, 1, 4], axis=1)\n",
    "    dataframe = dataframe.rename({2: \"x\", 3: \"y\"}, axis=1)\n",
    "    dataframe.loc[:, \"x\"] = dataframe.loc[:,\"x\"].str.replace(\"x\", \"\", case=False).astype(np.int)\n",
    "    dataframe.loc[:, \"y\"] = dataframe.loc[:,\"y\"].str.replace(\"y\", \"\", case=False).astype(np.int)\n",
    "    return dataframe\n",
    "\n",
    "def get_patient_dataframe(patient_id):\n",
    "    df_0 = get_cancer_dataframe(patient_id, \"0\")\n",
    "    df_1 = get_cancer_dataframe(patient_id, \"1\")\n",
    "    patient_df = pd.concat([df_0, df_1], ignore_index=True)\n",
    "    return patient_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise_breast_tissue_base(patient_id, pred_df=None):\n",
    "    example_df = get_patient_dataframe(patient_id)\n",
    "    max_point = [example_df.y.max()-1, example_df.x.max()-1]\n",
    "    grid = 255*np.ones(shape=(max_point[0] + 50, max_point[1] + 50, 3)).astype(np.uint8)\n",
    "    mask = 255*np.ones(shape=(max_point[0] + 50, max_point[1] + 50, 3)).astype(np.uint8)\n",
    "    if pred_df is not None:\n",
    "        patient_df = pred_df[pred_df.patient_id == patient_id].copy()\n",
    "    mask_proba = np.zeros(shape=(max_point[0] + 50, max_point[1] + 50, 1)).astype(np.float)\n",
    "    \n",
    "    broken_patches = []\n",
    "    for n in range(len(example_df)):\n",
    "        try:\n",
    "            image = imread(example_df.path.values[n])\n",
    "            target = example_df.target.values[n]\n",
    "            x_coord = np.int(example_df.x.values[n])\n",
    "            y_coord = np.int(example_df.y.values[n])\n",
    "            x_start = x_coord - 1\n",
    "            y_start = y_coord - 1\n",
    "            x_end = x_start + 50\n",
    "            y_end = y_start + 50\n",
    "\n",
    "            grid[y_start:y_end, x_start:x_end] = image\n",
    "            if target == 1:\n",
    "                mask[y_start:y_end, x_start:x_end, 0] = 250\n",
    "                mask[y_start:y_end, x_start:x_end, 1] = 0\n",
    "                mask[y_start:y_end, x_start:x_end, 2] = 0\n",
    "            if pred_df is not None:\n",
    "                proba = patient_df[(patient_df.x==x_coord) & (patient_df.y==y_coord)].proba\n",
    "                mask_proba[y_start:y_end, x_start:x_end, 0] = np.float(proba)\n",
    "\n",
    "        except ValueError:\n",
    "            broken_patches.append(example_df.path.values[n])\n",
    "    \n",
    "    return grid, mask, broken_patches, mask_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise_breast_tissue(patient_id):\n",
    "    grid, mask, broken_patches,_ = visualise_breast_tissue_base(patient_id)\n",
    "\n",
    "    fig, ax = plt.subplots(1,2,figsize=(20,10))\n",
    "    ax[0].imshow(grid, alpha=0.9)\n",
    "    ax[1].imshow(mask, alpha=0.8)\n",
    "    ax[1].imshow(grid, alpha=0.7)\n",
    "    ax[0].grid(False)\n",
    "    ax[1].grid(False)\n",
    "    for m in range(2):\n",
    "        ax[m].set_xlabel(\"X-coord\")\n",
    "        ax[m].set_ylabel(\"Y-coord\")\n",
    "    ax[0].set_title(\"Breast tissue slice of patient: \" + patient_id)\n",
    "    ax[1].set_title(\"Cancer tissue colored red \\n of patient: \" + patient_id)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise_breast_tissue_binary(patient_id):\n",
    "        \n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "    example_df = get_patient_dataframe(patient_id)\n",
    "\n",
    "    ax.scatter(example_df.x.values, example_df.y.values, c=example_df.target.values, cmap=\"coolwarm\", s=20)\n",
    "    ax.set_title(\"Patient \" + patient_id)\n",
    "    ax.set_xlabel(\"X coord\")\n",
    "    ax.set_ylabel(\"Y coord\")\n",
    "    ax.set_aspect('equal')  # Set aspect ratio to 'equal' to preserve original orientation\n",
    "    ax.invert_yaxis()  # Reverse the y-axis direction\n",
    "\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener 5 elementos aleatorios de la lista\n",
    "random_patient_ids = random.sample(patient_ids, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id in random_patient_ids: #ids_unique:\n",
    "    print(\"Patient's ID: \", id)\n",
    "    visualise_breast_tissue(id)\n",
    "    visualise_breast_tissue_binary(id)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
